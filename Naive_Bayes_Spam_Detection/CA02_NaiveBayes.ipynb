{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CA02_NaiveBayes.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJM5tizOxkGT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GL1VIK2GxqjO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#The goal of this cell is to build a Dictionary of the 3000 most common words from all the email content. \n",
        "def make_Dictionary(root_dir):\n",
        "  all_words = []\n",
        "  #construct a dictionary for all words and symbols\n",
        "  emails = [os.path.join(root_dir,f) for f in os.listdir(root_dir)]\n",
        "  #create a path for the folder that contain the emails\n",
        "  for mail in emails:\n",
        "    with open(mail) as m:\n",
        "      #check for directories and list everything in the directory (files and directories)\n",
        "      for line in m:\n",
        "        words = line.split()\n",
        "        all_words += words\n",
        "        #separate each word in the email \n",
        "  dictionary = Counter(all_words)\n",
        "  #count all the words in the dictionary\n",
        "  list_to_remove = list(dictionary)\n",
        "\n",
        "  for item in list_to_remove:\n",
        "    if item.isalpha() == False: \n",
        "      del dictionary[item]\n",
        "      #remove non-alpha numeric characters\n",
        "    elif len(item) == 1:\n",
        "      del dictionary[item]\n",
        "      #remove single character (words of length 1)\n",
        "  dictionary = dictionary.most_common(3000)\n",
        "  #extract only 3000 of the most common words\n",
        "  return dictionary\n",
        "  #return to Dictionary"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqJNX11cybFF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#The goal of this cell is to extract feature columns and populates their values \n",
        "def extract_features(mail_dir):\n",
        "  files = [os.path.join(mail_dir,fi) for fi in os.listdir(mail_dir)]\n",
        "  features_matrix = np.zeros((len(files),3000))\n",
        "  #generate feature matrix of 3000 columns and rows tthat are equal to the number of email files\n",
        "  train_labels = np.zeros(len(files))\n",
        "  #generate label for training dataset\n",
        "  count = 1;\n",
        "  docID = 0;\n",
        "  for fil in files:\n",
        "    with open(fil) as fi:\n",
        "      for i, line in enumerate(fi):\n",
        "        #check each line in the email\n",
        "        if i ==2:\n",
        "          #content start from the third line\n",
        "          words = line.split()\n",
        "          #separate line into words\n",
        "          for word in words:\n",
        "            wordID = 0\n",
        "            for i, d in enumerate(dictionary):\n",
        "              #check the dictionary with the 3000 most common words from the previous cell\n",
        "              if d[0] == word:\n",
        "                wordID = i\n",
        "                features_matrix[docID,wordID] = words.count(word)\n",
        "                #add the common word to a feature matrix\n",
        "      train_labels[docID] = 0;\n",
        "      #create a labelled data column\n",
        "      filepathTokens = fil.split('/')\n",
        "      lastToken = filepathTokens[len(filepathTokens)-1]\n",
        "      if lastToken.startswith(\"spmsg\"):\n",
        "        #categorize email that contains 'spmsmg' as spam\n",
        "        train_labels[docID] = 1;\n",
        "        count = count + 1\n",
        "      docID = docID + 1\n",
        "  return features_matrix, train_labels\n",
        "  #return the feature dataset and the label column"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yS2OkLMwynyo",
        "colab_type": "code",
        "outputId": "aeef8341-8c9e-4726-e70b-197351bb506c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "#The following cell is the main program that call the above two cells and execute \n",
        "TRAIN_DIR = '/content/drive/My Drive/MSBA_Colab_2020/ML_Algorithms/CA02/Data/train-mails'\n",
        "TEST_DIR = '/content/drive/My Drive/MSBA_Colab_2020/ML_Algorithms/CA02/Data/test-mails'\n",
        "#separate the data into trainining and testing dataset\n",
        "\n",
        "dictionary = make_Dictionary(TRAIN_DIR)\n",
        "#create a dictionary for the frequent words\n",
        "\n",
        "print (\"reading and processing emails from TRAIN and TEST folders\")\n",
        "features_matrix, labels = extract_features(TRAIN_DIR)\n",
        "#create feature matrix for training data\n",
        "test_features_matrix, test_labels = extract_features(TEST_DIR)\n",
        "#create feature matrix for testing data\n",
        "\n",
        "model = GaussianNB()\n",
        "#use Gausian model algorithm\n",
        "#Gausian model is used in classification and assume the data follows normal distribution\n",
        "\n",
        "print (\"Training Model using Gaussian Naibe Bayes algorithm .....\")\n",
        "model.fit(features_matrix, labels)\n",
        "#train the model with traning dataset\n",
        "print (\"Training completed\")\n",
        "print (\"testing trained model to predict Test Data labels\")\n",
        "predicted_labels = model.predict(test_features_matrix)\n",
        "#test for spam messages\n",
        "print (\"Completed classification of the Test Data .... now printing Accuracy Score by comparing the Predicted Labels with the Test Labels:\")\n",
        "print (accuracy_score(test_labels, predicted_labels))\n",
        "#print the model performance based on the accuracy score (percentage of correct prediction)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "reading and processing emails from TRAIN and TEST folders\n",
            "Training Model using Gaussian Naibe Bayes algorithm .....\n",
            "Training completed\n",
            "testing trained model to predict Test Data labels\n",
            "Completed classification of the Test Data .... now printing Accuracy Score by comparing the Predicted Labels with the Test Labels:\n",
            "0.9615384615384616\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}